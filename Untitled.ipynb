{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Tuple, List, Dict, Iterable, Callable, Union\n",
    "\n",
    "import numpy\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _first_true(iterable: List, pred: Callable[[Tuple[str, int]], Any]) -> Tuple[bytes, Any]:\n",
    "    \"\"\" --- from itertools : recipes ---\n",
    "    Returns the first true value in the iterable.\n",
    "    \"\"\"\n",
    "    return next(filter(pred, iterable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(order=True)\n",
    "class _BaseData:\n",
    "    # mappable member for when composited into SeriesData; sorted by\n",
    "    key: float = field(repr=True, init=False, compare=True)\n",
    "        \n",
    "    # initialization arguments; removed after initialization\n",
    "    file: h5py.File = field(repr=False, compare=False)\n",
    "    form: str = field(repr=False, compare=False)\n",
    "    code: str = field(repr=False, compare=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        supported: Dict[str, List[str]] = {'flash' : ['plt', 'chk']}\n",
    "        \n",
    "        # check for supported codes and formats\n",
    "        if self.code not in supported:\n",
    "            raise Exception(f'Code {self.code} is not supported; only code = {[*supported]}')\n",
    "            \n",
    "        if self.form not in supported[self.code]:\n",
    "            raise Exception(f'File format {self.form} is not supported; only form = {supported[self.code]}')\n",
    "\n",
    "        # process the file based on options\n",
    "        self.__init_process__()         \n",
    "\n",
    "        # verify properly initialized object\n",
    "        if not hasattr(self, 'key'):\n",
    "            raise NotImplementedError(f'{type(self)} does not initialize a key_float member')      \n",
    "            \n",
    "        # remove h5file and option members\n",
    "        delattr(self, 'file')\n",
    "        delattr(self, 'form')\n",
    "        delattr(self, 'code')\n",
    "        \n",
    "    #@abstractmethod   \n",
    "    def __init_process__(self) -> None:\n",
    "        raise NotImplementedError(f'{type(self)} does not implement an __init_process__ method')     \n",
    "    \n",
    "@dataclass\n",
    "class GeometryData(_BaseData):\n",
    "    blk_num: int = field(repr=False, init=False, compare=False)\n",
    "    blk_num_x: int = field(repr=True, init=False, compare=False)\n",
    "    blk_num_y: int = field(repr=True, init=False, compare=False)\n",
    "    blk_num_z: int = field(repr=True, init=False, compare=False)\n",
    "    blk_size_x: int = field(repr=True, init=False, compare=False)\n",
    "    blk_size_y: int = field(repr=True, init=False, compare=False)\n",
    "    blk_size_z: int = field(repr=True, init=False, compare=False)\n",
    "    blk_coords: numpy.ndarray = field(repr=False, init=False, compare=False)\n",
    "    blk_dict_x: Dict[float, int] = field(repr=True, init=False, compare=False)\n",
    "    blk_dict_y: Dict[float, int] = field(repr=True, init=False, compare=False)\n",
    "    blk_dict_z: Dict[float, int] = field(repr=True, init=False, compare=False)\n",
    "\n",
    "    grd_type: str = field(repr=True, init=False, compare=False)\n",
    "    grd_dim: int = field(repr=True, init=False, compare=False)\n",
    "    grd_size: int = field(repr=False, init=False, compare=False)\n",
    "    grd_size_x: int = field(repr=False, init=False, compare=False)\n",
    "    grd_size_y: int = field(repr=False, init=False, compare=False)\n",
    "    grd_size_z: int = field(repr=False, init=False, compare=False)\n",
    "        \n",
    "    def __init_process__(self) -> None:\n",
    "        # pull relavent data from hdf5 file object\n",
    "        sim_info: List[Tuple[int, bytes]] = list(self.file['sim info'])\n",
    "        coordinates: numpy.ndarray = self.file['coordinates']\n",
    "        int_runtime: List[Tuple[bytes, int]] = list(self.file['integer runtime parameters'])\n",
    "        int_scalars: List[Tuple[bytes, int]] = list(self.file['integer scalars'])\n",
    "        real_scalars: List[Tuple[bytes, float]] = list(self.file['real scalars'])\n",
    "            \n",
    "        # initialize mappable keys\n",
    "        self.key = float(_first_true(real_scalars, lambda l: 'time' in str(l[0]))[1])\n",
    "\n",
    "        # initialize grid type\n",
    "        setup_call: str = _first_true(sim_info, lambda l: l[0] == 9)[1].decode('utf-8')\n",
    "        if setup_call.find('+ug') != -1:\n",
    "            self.grd_type = 'uniform'\n",
    "        elif setup_call.find('+pm4dev') != -1:\n",
    "            self.grd_type = 'paramesh'\n",
    "        else:\n",
    "            raise Exception(f'Unable to determine grid type from sim info field')\n",
    "\n",
    "        # initialize grid dimensionality\n",
    "        self.grd_dim = _first_true(int_scalars, lambda l: 'dimensionality' in str(l[0]))[1]\n",
    "\n",
    "        # initialize coordinates of blocks\n",
    "        self.blk_coords = numpy.ndarray(coordinates.shape, dtype=numpy.dtype(float))\n",
    "        self.blk_coords[:, :] = coordinates\n",
    "\n",
    "        # initialize block data\n",
    "        if self.grd_type == 'uniform':\n",
    "            self.blk_num = _first_true(int_scalars, lambda l: 'globalnumblocks' in str(l[0]))[1] \n",
    "            self.blk_num_x = _first_true(int_runtime, lambda l: 'iprocs' in str(l[0]))[1]\n",
    "            self.blk_num_y = _first_true(int_runtime, lambda l: 'jprocs' in str(l[0]))[1]\n",
    "            self.blk_num_z = 1\n",
    "            self.blk_size_x = _first_true(int_scalars, lambda l: 'nxb' in str(l[0]))[1]\n",
    "            self.blk_size_y = _first_true(int_scalars, lambda l: 'nyb' in str(l[0]))[1]\n",
    "            self.blk_size_z = _first_true(int_scalars, lambda l: 'nzb' in str(l[0]))[1]\n",
    "\n",
    "        elif self.grd_type == 'paramesh':\n",
    "            self.blk_num = _first_true(int_scalars, lambda l: 'globalnumblocks' in str(l[0]))[1] \n",
    "            self.blk_num_x = _first_true(int_runtime, lambda l: 'nblockx' in str(l[0]))[1]\n",
    "            self.blk_num_y = _first_true(int_runtime, lambda l: 'nblocky' in str(l[0]))[1]\n",
    "            self.blk_num_z = 1\n",
    "            self.blk_size_x = _first_true(int_scalars, lambda l: 'nxb' in str(l[0]))[1]\n",
    "            self.blk_size_y = _first_true(int_scalars, lambda l: 'nyb' in str(l[0]))[1]\n",
    "            self.blk_size_z = _first_true(int_scalars, lambda l: 'nzb' in str(l[0]))[1]\n",
    "\n",
    "        else:\n",
    "            pass # other grid handling operations\n",
    "\n",
    "        # initialize block to grid mapping dictionaries\n",
    "        self.blk_dict_x = {}\n",
    "        keys: List[int] = sorted(set(self.blk_coords[:, 0]))\n",
    "        for key, val in zip(keys, range(self.blk_num_x)):\n",
    "            self.blk_dict_x[key] = val\n",
    "\n",
    "        self.blk_dict_y = {}\n",
    "        keys = sorted(set(self.blk_coords[:, 1]))\n",
    "        for key, val in zip(keys, range(self.blk_num_y)):\n",
    "            self.blk_dict_y[key] = val \n",
    "          \n",
    "        self.blk_dict_z = None\n",
    "\n",
    "        # initialize grid data\n",
    "        self.grd_size_x = self.blk_num_x * self.blk_size_x\n",
    "        self.grd_size_y = self.blk_num_y * self.blk_size_y\n",
    "        self.grd_size_z = self.blk_num_z * self.blk_size_z\n",
    "        self.grd_size = self.grd_size_x * self.grd_size_y * self.grd_size_z\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        fields = ['grd_type', 'blk_num', 'blk_num_x', 'blk_num_y', 'blk_num_z', \n",
    "                  'blk_size_x', 'blk_size_y', 'blk_size_z']\n",
    "        return f'GeometryData(key={self.key:.4f}, ' + ', '.join(field + \n",
    "            '=' + str(getattr(self, field)) for field in fields) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_transpose(source: List[Any], names: Iterable[str]) -> List[List[Any]]:\n",
    "    return [list(map(lambda obj: getattr(obj, name), source)) for name in names]\n",
    "\n",
    "class _SliceList(list):\n",
    "    def __getitem__(self, key: Union[int, slice, Iterable[str]]) -> Union[List[List[Any]], '_SliceList']:\n",
    "        if isinstance(key, str):\n",
    "            return _filter_transpose(self, [key])        \n",
    "        elif hasattr(key, '__iter__'):\n",
    "            return _filter_transpose(self, list(key))\n",
    "        elif isinstance(key, int):\n",
    "            return self.__class__([super().__getitem__(key)])\n",
    "        else:\n",
    "            return self.__class__(super().__getitem__(key))\n",
    "    def __add__(self, other):\n",
    "        return self.__class__(super().__add__(other))\n",
    "    def __iadd__(self, other):\n",
    "        return self.__class__(super().__iadd__(other))    \n",
    "    def __mul__(self, other):\n",
    "        return self.__class__(super().__mul__(other))\n",
    "    def __rmul__(self, other):\n",
    "        return self.__class__(super().__rmul__(other))\n",
    "    def __imul__(self, other):\n",
    "        return self.__class__(super().__imul__(other))\n",
    "        \n",
    "class SeriesData:\n",
    "    \"\"\"\n",
    "    Implements a container of _BaseData (or inherited) instances, providing the following functionality\n",
    "      (1) std::vector-like element-wise access (w/ slicing), resize, append, and remove\n",
    "      (2) dictionary-like mappable access with float or string; views of _BaseData.key\n",
    "      (3) container remains ordered based on each elements _BaseData.key\n",
    "        \n",
    "      Usage\n",
    "      -----\n",
    "      create      series = SeriesData(capacity: int)    creates empty container\n",
    "      resize      series.resize(size)                   shrink/grow from the end\n",
    "      append      series.append(value)\n",
    "      remove      series.remove(key)\n",
    "      access      series[key]             Note that type(key):\n",
    "                                            int    : element-wise access\n",
    "                                            float  : element with _BaseData.key = key\n",
    "                                            string :            -- same --\n",
    "                                            \n",
    "      Additional notes w.r.t. element-wise access:\n",
    "        series[key: int] = value     key > size : equivalent to series.append(value)\n",
    "        series[key: int] = value     key < size : will overwrite element @ key\n",
    "        series[key: float] = value   insert or overwrite existing element w/ equal key \n",
    "        series[key: string] = value              -- same --\n",
    "    \"\"\"\n",
    "    def __init__(self, size: int):\n",
    "        self._data: _SliceList[_BaseData] = _SliceList([None for _ in range(size)])\n",
    "        self._capacity: int = size\n",
    "        self._size: int = 0\n",
    "        self._map_float: Dict[float, int] = OrderedDict()             \n",
    "        self._map_string: Dict[str, int] = {}\n",
    "            \n",
    "    def __grow__(self, size: int = None) -> None:\n",
    "        if size is None:\n",
    "            size = self._capacity\n",
    "        self._data = self._data + [None for _ in range(size)]\n",
    "        self._capacity = len(self._data)\n",
    "        \n",
    "    def __build_map__(self) -> None:\n",
    "        self._map_float = OrderedDict([(item.key, i) for i, item in enumerate(self._data[:self._size])])\n",
    "        self._map_string = dict([(str(item), i) for i, item in enumerate(iter(self._map_float))])   \n",
    "        \n",
    "    def __sort__(self) -> None:\n",
    "        self._data = _SliceList(sorted(self._data[:self._size])) + self._data[self._size:]\n",
    "        self.__build_map__() \n",
    "        \n",
    "    def __append__(self, value: _BaseData) -> None:\n",
    "        self._size += 1\n",
    "        self._data[self._size - 1] = value\n",
    "        self._map_float[value.key] = self._size - 1\n",
    "        self._map_string[str(value.key)] = self._size - 1\n",
    "\n",
    "    def __getitem__(self, key: Any) -> Union[List[_BaseData], _BaseData]:\n",
    "        if isinstance(key, slice):\n",
    "            return self._data[:self._size][key.start : key.stop : key.step] \n",
    "        elif isinstance(key, int):\n",
    "            return self._data[key]\n",
    "        elif isinstance(key, float):\n",
    "            return self._data[self._map_float[key]]\n",
    "        elif isinstance(key, str):\n",
    "            return self._data[self._map_string[key]]        \n",
    "        else:\n",
    "            raise Exception(f'Mapping of type, {type(key)}, is not supported')\n",
    "\n",
    "    def __setitem__(self, key: Any, value: _BaseData) -> None:            \n",
    "        if isinstance(key, int):            \n",
    "            if self._size <= key and key < self._capacity:\n",
    "                if value.key in self._map_float:\n",
    "                    raise Exception(f'Nonunique key provided; {value.key} @ index {self._map_float[value.key]}')\n",
    "                else:\n",
    "                    self.append(value)                   \n",
    "            elif key >= 0:\n",
    "                if value.key in self._map_float and key != self._map_float[value.key]:\n",
    "                    raise Exception(f'Nonunique key location mismatch; identical key @ {self._map_float[value.key]}')\n",
    "                else:                  \n",
    "                    self._data[key] = value                 \n",
    "                    self.__sort__()                   \n",
    "            else:\n",
    "                raise Exception(f'Invalid key, {key}, provided to __setitem__')                \n",
    "        elif isinstance(key, float):\n",
    "            if key != value.key:\n",
    "                raise Exception(f'Nonidentical keys provided; {key} != {value.key}')\n",
    "            self.append(value)                    \n",
    "        elif isinstance(key, str):\n",
    "            if key != str(value.key):\n",
    "                raise Exception(f'Nonidentical keys provided; {key} != {str(value.key)}')\n",
    "            if key in self._map_string:\n",
    "                self._data[self._map_string[key]] = value                   \n",
    "            else:\n",
    "                self.append(value)\n",
    "        else:\n",
    "            raise Exception(f'Mapping of type, {type(key)}, is not supported')                \n",
    "                \n",
    "    def __str__(self) -> str:\n",
    "        return '[' + ',\\n '.join(item.__str__() for item in self._data[:self._size]) + ']'\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return '[' + ',\\n '.join(item.__repr__() for item in self._data[:self._size]) + ']'\n",
    "    \n",
    "    def resize(self, size: int) -> None:\n",
    "        \"\"\"\n",
    "        Resizes the container based on the supplied size;\n",
    "          if the size is > the container size, the container will grow/shrink\n",
    "          accordingly and the data will remain uneffected\n",
    "          \n",
    "          if the size is < the container size, data will be eliminated from the\n",
    "          end of the container to match the supplied size\n",
    "        \"\"\"        \n",
    "        if size > self._capacity:\n",
    "            self.__grow__(size)\n",
    "        elif size > self._size:\n",
    "            self._data = self._data[:size]\n",
    "            self._capacity = size\n",
    "        elif size >= 0:\n",
    "            self._data = self._data[:size]\n",
    "            self.__build_map__()\n",
    "            self._capacity = size\n",
    "            self._size = size   \n",
    "        else:\n",
    "            raise Exception(f'Invalid size, {size}, provided to resize()') \n",
    "            \n",
    "    def remove(self, key: Any) -> None:\n",
    "        \"\"\"\n",
    "        Removes the element according to the supplied 'key'\n",
    "            type(key) determines how location is identified\n",
    "                int    : element-wise based on sorted data\n",
    "                float  : element with _BaseData.key = key\n",
    "                string :            -- same --        \n",
    "        \"\"\"\n",
    "        if isinstance(key, int):\n",
    "            if self._size <= key and key < self._capacity:\n",
    "                pass\n",
    "            elif key >= 0:\n",
    "                self._data = self._data[:key] + self._data[key + 1:] + [None]\n",
    "                self._size -= 1\n",
    "                self.__build_map__() \n",
    "            else:\n",
    "                raise Exception(f'Invalid key, {key}, provided to remove()') \n",
    "        elif isinstance(key, float):\n",
    "            if key in self._map_float:\n",
    "                self._data = self._data[:self._map_float[key]] + self._data[self._map_float[key] + 1:] + [None]\n",
    "                self._size -= 1\n",
    "                self.__build_map__()\n",
    "        elif isinstance(key, str):\n",
    "            if key in self._map_string:\n",
    "                self._data = self._data[:self._map_string[key]] + self._data[self._map_string[key] + 1:] + [None]\n",
    "                self._size -= 1\n",
    "                self.__build_map__()    \n",
    "        else:\n",
    "            raise Exception(f'Mapping of type, {type(key)}, is not supported')     \n",
    "    \n",
    "    def append(self, value: _BaseData) -> None:\n",
    "        \"\"\"\n",
    "        Appends an element to the container according to the supplied 'value';\n",
    "        if value.key is identical to the key of an element in the container\n",
    "        append will over write the data stored at that element\n",
    "        \"\"\"\n",
    "        if value.key in self._map_float:\n",
    "            self._data[self._map_float[value.key]] = value \n",
    "            \n",
    "        else:        \n",
    "            if self._size < self._capacity:           \n",
    "                is_sorted: bool = True\n",
    "                if self._size > 0 and value.key < next(reversed(self._map_float)):\n",
    "                    is_sorted = False \n",
    "                self.__append__(value)                        \n",
    "                if not is_sorted:\n",
    "                    self.__sort__()            \n",
    "            else:\n",
    "                self.__grow__()\n",
    "                self.append(value)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = h5py.File('INS_Rayleigh_Benard_hdf5_plt_cnt_0000', 'r')\n",
    "data1 = GeometryData(file=h5file, form='plt', code='flash')\n",
    "data1.key = data1.key + 10\n",
    "\n",
    "data2 = GeometryData(file=h5file, form='plt', code='flash')\n",
    "\n",
    "data3 = GeometryData(file=h5file, form='plt', code='flash')\n",
    "data3.key = data3.key - 10\n",
    "\n",
    "data4 = GeometryData(file=h5file, form='plt', code='flash')\n",
    "data4.key = data4.key - 20\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GeometryData(key=40.2500112134101, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3),\n",
       " GeometryData(key=50.2500112134101, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3),\n",
       " GeometryData(key=60.2500112134101, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3),\n",
       " GeometryData(key=70.25001121341009, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3)]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = SeriesData(8)\n",
    "series.append(data2)\n",
    "series.append(data3)\n",
    "series.append(data4)\n",
    "series[0] = data1\n",
    "series.remove(0)\n",
    "series[3] = data4\n",
    "series.append(data1)\n",
    "series[6] = data3\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__._SliceList'>\n",
      "<class '__main__._SliceList'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(series._data))\n",
    "print(type(series[:2]))\n",
    "print(type(series[:2]['blk_num']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GeometryData(key=40.2500112134101, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3), GeometryData(key=50.2500112134101, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3), GeometryData(key=60.2500112134101, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3), GeometryData(key=70.25001121341009, blk_num_x=6, blk_num_y=6, blk_num_z=1, blk_size_x=12, blk_size_y=12, blk_size_z=72, blk_dict_x={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_y={0.0833333358168602: 0, 0.25: 1, 0.4166666567325592: 2, 0.5833333134651184: 3, 0.75: 4, 0.9166666865348816: 5}, blk_dict_z=None, grd_type='uniform', grd_dim=3), None, None, None, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[36, 36, 36, 36],\n",
       " ['uniform', 'uniform', 'uniform', 'uniform'],\n",
       " [40.2500112134101, 50.2500112134101, 60.2500112134101, 70.25001121341009]]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(series._data)\n",
    "series[:]['blk_num', 'grd_type', 'key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [5, 3]\n",
    "l = s[0]\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
